# Reusable Code Directives Validation Workflow
# This workflow can be called by other repositories to validate code using the Code Directives SDK

name: Code Directives Validation

on:
  workflow_call:
    inputs:
      path:
        description: 'Path to validate (default: ./)'
        required: false
        type: string
        default: './'
      standards:
        description: 'Standards to check (comma-separated: code,security,performance)'
        required: false
        type: string
        default: 'code,security,performance'
      auto_fix:
        description: 'Automatically fix issues where possible'
        required: false
        type: boolean
        default: true
      node_version:
        description: 'Node.js version to use'
        required: false
        type: string
        default: '18'
      fail_on_error:
        description: 'Fail the workflow if validation fails'
        required: false
        type: boolean
        default: true
      generate_report:
        description: 'Generate validation report'
        required: false
        type: boolean
        default: true
    outputs:
      validation_score:
        description: 'Overall validation score (0-100)'
        value: ${{ jobs.validate.outputs.score }}
      validation_passed:
        description: 'Whether validation passed'
        value: ${{ jobs.validate.outputs.passed }}
      issues_count:
        description: 'Number of issues found'
        value: ${{ jobs.validate.outputs.issues_count }}
      fixes_count:
        description: 'Number of issues automatically fixed'
        value: ${{ jobs.validate.outputs.fixes_count }}

env:
  NODE_VERSION: ${{ inputs.node_version }}

jobs:
  validate:
    name: Validate with Code Directives
    runs-on: ubuntu-latest
    
    outputs:
      score: ${{ steps.validate.outputs.score }}
      passed: ${{ steps.validate.outputs.passed }}
      issues_count: ${{ steps.validate.outputs.issues_count }}
      fixes_count: ${{ steps.validate.outputs.fixes_count }}
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          # Fetch full history for better analysis
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install Dependencies
        run: |
          # Install project dependencies if package.json exists
          if [ -f package.json ]; then
            npm ci
          fi
          
          # Install Code Directives SDK globally for validation
          npm install -g @company/code-directives
      
      - name: Run Code Directives Validation
        id: validate
        run: |
          echo "🔍 Running Code Directives validation..."
          echo "Path: ${{ inputs.path }}"
          echo "Standards: ${{ inputs.standards }}"
          echo "Auto-fix: ${{ inputs.auto_fix }}"
          echo ""
          
          # Build validation command
          VALIDATE_CMD="bp validate --path '${{ inputs.path }}' --standards '${{ inputs.standards }}'"
          
          if [ "${{ inputs.auto_fix }}" = "true" ]; then
            VALIDATE_CMD="$VALIDATE_CMD --fix"
          fi
          
          if [ "${{ inputs.generate_report }}" = "true" ]; then
            VALIDATE_CMD="$VALIDATE_CMD --report --output validation-report.json"
          fi
          
          # Run validation and capture output
          set +e  # Don't exit on validation failure
          eval $VALIDATE_CMD > validation-output.txt 2>&1
          VALIDATION_EXIT_CODE=$?
          set -e
          
          # Display validation output
          cat validation-output.txt
          
          # Parse results if report was generated
          if [ "${{ inputs.generate_report }}" = "true" ] && [ -f validation-report.json ]; then
            # Extract metrics from JSON report
            SCORE=$(jq -r '.score // 0' validation-report.json)
            PASSED=$(jq -r '.passed // false' validation-report.json)
            ISSUES_COUNT=$(jq -r '.issues | length' validation-report.json)
            FIXES_COUNT=$(jq -r '.fixed | length' validation-report.json)
            
            echo "score=$SCORE" >> $GITHUB_OUTPUT
            echo "passed=$PASSED" >> $GITHUB_OUTPUT
            echo "issues_count=$ISSUES_COUNT" >> $GITHUB_OUTPUT  
            echo "fixes_count=$FIXES_COUNT" >> $GITHUB_OUTPUT
            
            # Add to step summary
            echo "## 📊 Validation Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Overall Score:** $SCORE/100" >> $GITHUB_STEP_SUMMARY
            echo "**Status:** $([ "$PASSED" = "true" ] && echo "✅ PASSED" || echo "❌ FAILED")" >> $GITHUB_STEP_SUMMARY
            echo "**Issues Found:** $ISSUES_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "**Issues Fixed:** $FIXES_COUNT" >> $GITHUB_STEP_SUMMARY
            
            # Add detailed breakdown if available
            if [ "$ISSUES_COUNT" -gt 0 ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### 🔍 Issue Breakdown" >> $GITHUB_STEP_SUMMARY
              
              # Extract issue types and counts
              jq -r '.issues | group_by(.type) | .[] | "\(length) \(.[0].type) issues"' validation-report.json >> $GITHUB_STEP_SUMMARY
            fi
          else
            # Fallback: determine pass/fail from exit code
            PASSED=$([ $VALIDATION_EXIT_CODE -eq 0 ] && echo "true" || echo "false")
            echo "passed=$PASSED" >> $GITHUB_OUTPUT
            echo "score=0" >> $GITHUB_OUTPUT
            echo "issues_count=0" >> $GITHUB_OUTPUT
            echo "fixes_count=0" >> $GITHUB_OUTPUT
          fi
          
          # Set final exit code for workflow
          if [ "${{ inputs.fail_on_error }}" = "true" ] && [ "$VALIDATION_EXIT_CODE" -ne 0 ]; then
            echo "❌ Validation failed and fail_on_error is true"
            exit $VALIDATION_EXIT_CODE
          fi
      
      - name: Upload Validation Report
        uses: actions/upload-artifact@v3
        if: inputs.generate_report == true
        with:
          name: code-directives-validation-report
          path: |
            validation-report.json
            validation-output.txt
          retention-days: 7
      
      - name: Comment on PR with Results
        if: github.event_name == 'pull_request' && steps.validate.outputs.score != ''
        uses: actions/github-script@v6
        with:
          script: |
            const score = '${{ steps.validate.outputs.score }}';
            const passed = '${{ steps.validate.outputs.passed }}' === 'true';
            const issuesCount = '${{ steps.validate.outputs.issues_count }}';
            const fixesCount = '${{ steps.validate.outputs.fixes_count }}';
            
            const status = passed ? '✅ PASSED' : '❌ FAILED';
            const scoreColor = score >= 80 ? '🟢' : score >= 60 ? '🟡' : '🔴';
            
            const comment = `## ${scoreColor} Code Directives Validation Results
            
            **Overall Score:** ${score}/100  
            **Status:** ${status}  
            **Issues Found:** ${issuesCount}  
            **Issues Fixed:** ${fixesCount}  
            
            ### Standards Checked
            - ${{ inputs.standards }}
            
            ${passed ? 
              '🎉 Great work! Your code meets all the required standards.' : 
              '💡 Please review the validation report and address the issues found.'
            }
            
            ---
            *Validated by [Code Directives SDK](https://github.com/ramsaptami/code-directives)*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  # Generate badges for README updates
  generate-badges:
    name: Generate Status Badges
    runs-on: ubuntu-latest
    needs: validate
    if: always()
    
    steps:
      - name: Create Validation Badge
        run: |
          SCORE="${{ needs.validate.outputs.score }}"
          PASSED="${{ needs.validate.outputs.passed }}"
          
          # Determine badge color based on score
          if [ "$PASSED" = "true" ]; then
            COLOR="brightgreen"
            MESSAGE="passed"
          elif [ "$SCORE" -ge 80 ]; then
            COLOR="green"
            MESSAGE="$SCORE%2F100"
          elif [ "$SCORE" -ge 60 ]; then
            COLOR="yellow"  
            MESSAGE="$SCORE%2F100"
          else
            COLOR="red"
            MESSAGE="$SCORE%2F100"
          fi
          
          echo "## 🏆 Validation Badge" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Add this badge to your README:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```markdown' >> $GITHUB_STEP_SUMMARY
          echo "[![Code Directives](https://img.shields.io/badge/Code%20Directives-$MESSAGE-$COLOR)](https://github.com/ramsaptami/code-directives)" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY